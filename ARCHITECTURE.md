# Architecture Overview

## 1. Project Structure
The repository is organised into three main layers: API (`src/app`), RAG building blocks (`src/rag`), and agent orchestration (`src/graph`), plus docker/dev tooling at the root.

```
multiagent-rag/
├─ README.md                                # Project quickstart and usage guide 
├─ ARCHITECTURE.md                          # This file
├─ requirements.txt                         # Pinned Python dependencies for the API server
├─ .env                                     # Local environment configuration for settings 
├─ ui.html                                  # Minimal demo UI served by FastAPI, generated by an AI
├─ docker-compose.yaml                      # Local multi-container stack: FastAPI app + Qdrant vector DB + Redis memory store
├─ Dockerfile                               # Container build for the FastAPI app
├─ data/                                    # Local document directory mounted into the container for path-based ingestion
├─ src/
│  ├─ app/                                  # FastAPI application layer
│  │  ├─ main.py                            # App creation, routers, health and UI serving
│  │  ├─ api/                               # FastAPI web layer
│  │  │  ├─ __init__.py
│  │  │  ├─ deps.py                         # FastAPI dependency injection helpers
│  │  │  ├─ routers/                        # FastAPI route modules grouping endpoints by domain
│  │  │  │  ├─ __init__.py
│  │  │  │  ├─ chat.py                      # Converts client messages to LangChain messages
│  │  │  │  └─ ingest.py                    # Indexes documents from local file paths
│  │  ├─ core/                              # Cross-cutting application utilities 
│  │  │  ├─ __init__.py
│  │  │  ├─ config.py                       # Pydantic settings loaded from .env
│  │  │  └─ logging.py                      # Structlog JSON logging setup
│  │  └─ schemas/                           # Pydantic request/response models 
│  │     ├─ __init__.py
│  │     ├─ chat.py                         # Pydantic models for /chat request/response
│  │     └─ ingest.py                       # Pydantic models for /ingest request/response 
│  ├─ rag/                                  # Reusable Retrieval-Augmented Generation primitives
│  │  ├─ __init__.py
│  │  ├─ ingestion/                         # Document ingestion pipeline components
│  │  │  ├─ __init__.py
│  │  │  ├─ loaders.py                      # Document loaders that read supported file formats 
│  │  │  ├─ chunking.py                     # Chunking utilities
│  │  │  └─ indexing.py                     # Indexing pipeline entrypoint
│  │  ├─ vectorstore/                       # Abstractions and clients for the vector database
│  │  │  ├─ __init__.py
│  │  │  └─ qdrant_client.py                # Qdrant client singleton and ensure_collection
│  │  ├─ retrieval/                         # Retrieval logic that turns a query into a ranked set of Document chunks 
│  │  │  ├─ __init__.py
│  │  │  ├─ hybrid_retriever.py             # Hybrid retrieval
│  │  │  └─ reranker.py                     # Deterministic lightweight reranker
│  │  ├─ llm/                               # LLM provider routing, adapters, and prompts
│  │  │  ├─ __init__.py
│  │  │  ├─ ollama_adapter.py               # LangChain compatible chat model wrapper for Ollama
│  │  │  ├─ models.py                       # Provider routing for planner/reasoning/citation LLMs
│  │  │  └─ prompts.py                      # Centralised system prompts 
│  │  └─ memory/                            # Conversation memory persistence utilities
│  │     ├─ __init__.py
│  │     └─ redis_memory.py                 # Redis helpers to load/save conversation summary
│  └─ graph/                                # LangGraph orchestration layer
│     ├─ __init__.py
│     ├─ state.py                           # Shared GraphState TypedDict contract for all nodes
│     ├─ nodes/                             # Individual agent nodes
│     │  ├─ __init__.py
│     │  ├─ clarify_agent.py                # Clarification node that asks the user for missing context
│     │  ├─ direct_answer.py                # Direct answer node for smalltalk/meta questions using only chat history 
│     │  ├─ retrieval_quality_gate.py       # Quality gate that retries retrieval once when too few documents are returned 
│     │  ├─ supervisor.py                   # Supervisor router node that chooses between clarify, direct answer, or RAG path
│     │  ├─ query_planner.py                # Planner node that drafts a short retrieval plan
│     │  ├─ retrieval_agent.py              # Retrieval node that calls HybridRetriever to fetch candidate documents
│     │  ├─ reasoning_agent.py              # Reasoning node that synthesizes an answer from retrieved context 
│     │  ├─ citation_agent.py               # Citation node that post processes the draft answer, attaches inline citation markers
│     │  └─ memory_agent.py                 # Memory node that loads a Redis summary/recent messages
│     └─ workflow.py                        # LangGraph StateGraph definition wiring all nodes
├─ docs/
│  ├─ document.pdf                          # Demo pdf document to ingest, contains the "Attention is all you need" paper
│  ├─ document.txt                          # Demo txt document to ingest, contains an AI generated financial report
│  └─ document.md                           # Demo md document to ingest, contains an AI generated wikipedia article on solar eclipses
└─ tests/
   ├─ test_ingestion_determinism.py         # Check that re-ingesting identical docs produces identical Qdrant point IDs
   ├─ test_hybrid_retriver_merge.py         # Check that HybridRetriever.retrieve() deduplicates candidates correctly
   ├─ test_citation_agent_guardrails.py     # Check that the citation_node() refuses when there are no documents
   └─  test_redis_memory_legacy_fallback.py # Check that load_memory_bundle_from_redis() can fall back to the chat:{session_id}
```

## 2. High-Level System Diagram
At runtime, the user interacts through either the static `ui.html` or any HTTP client, which then delegates to a compiled LangGraph workflow that may retrieve from Qdrant, persist memory in Redis, and call an LLM provider.
 
```text
[User / Browser]
    |
    |  HTTP: POST /ingest, POST /chat
    v
[FastAPI app (src/app/main.py)]
    |
    |  /chat -> LangGraph workflow (compiled)
    v
[LangGraph Orchestrator (src/graph/workflow.py)]
    |
    +--> [Redis]  (load/save conversation window + summary)
    |       ^ 
    |       |  session_id
    |       +-- src/rag/memory/redis_memory.py
    |
    +--> [Qdrant] (dense search + lexical scroll)
    |       ^
    |       +-- src/rag/vectorstore/qdrant_client.py
    |
    +--> [LLM Provider] (OpenAI or Ollama)
            ^
            +-- src/rag/llm/models.py + src/rag/llm/ollama_adapter.py
```     

## 3. Core Components

### 3.1. Frontend

Name: Demo UI (ui.html).

Description: A minimal single page UI that can ingest documents by container local paths (POST /ingest) and chat (POST /chat) while storing sessionId in localStorage and rendering returned citations.

Technologies: Plain HTML/CSS/JavaScript, served by FastAPI’s / route. 

Deployment: Packaged into the same Docker image as the API service and served from the container filesystem. 

### 3.2. Backend Services
#### 3.2.1. Multi-Agent RAG API (FastAPI)

Name: MultiAgent RAG API. 

Description: Exposes:
- POST /ingest: indexes documents from local file paths (developer/admin endpoint).
- POST /chat: converts client messages into LangChain messages, constructs initial GraphState, and invokes the LangGraph multi-agent workflow

Technologies: FastAPI + Uvicorn, Pydantic settings, structlog logging. 

Deployment: Docker container (Dockerfile) and local multi-service composition (docker-compose.yaml).

#### 3.2.2. Agent Orchestration (LangGraph)

Name: LangGraph workflow. 

Description: Orchestrates multiple specialised nodes operating over a shared GraphState contract.

Implements a retry loop for weak retrieval and branches for direct-answer and clarification paths.

Technologies: langgraph (StateGraph), LangChain message/document types. 

Deployment: Runs in-process inside the FastAPI container.

#### 3.2.3. RAG Core Library (src/rag)

Name: RAG primitives. 

Description:
- Retrieval: HybridRetriever performs dense vector search + lexical search in Qdrant, merges and reranks results.
- Reranking: simple_rerank provides deterministic, zero-external-call ranking as a placeholder. 
- LLM + embeddings: provider routing (OpenAI vs Ollama) and BGE embeddings factory. 
- Prompts: centralized system prompts for planner, reasoning, citations, and direct-answer.

Technologies: Qdrant client, Redis client, SentenceTransformers, OpenAI SDK, requests (Ollama adapter).

Deployment: Runs in-process inside the FastAPI container; Qdrant/Redis are external containers in compose.

## 4. Data Stores

### 4.1. Vector Store (Qdrant)

Name: Qdrant collection.

Type: Vector database.

Purpose: Stores embedded document chunks and associated payload metadata used for dense and lexical retrieval during chat.

Key Schemas/Collections: documents (default), with vector size 1024 by default and cosine distance. 

### 4.2. Conversation Memory Store (Redis)

Name: Redis chat memory store. 

Type: Cache memory. 

Purpose: Persists per-session conversation “recent messages” and a rolling summary with TTL, enabling multi-turn context across requests.

## 5. External Integrations / APIs

Serivce Name: LLM Provider (OpenAI or Ollama). 

Purpose: Powers query planning, reasoning synthesis, and citation post-processing.

Integration Method:
- OpenAI: SDK (openai client) via a minimal LangChain compatible wrapper.
- Ollama-like backend: HTTP POST {base_url}/generate using requests. 

## 6. Deployment & Infrastructure

Cloud Provider: None, local first Docker Compose is provided. 

Key Services Used (local/dev):
- Docker container for FastAPI (Dockerfile). 
- Qdrant container for vector storage. 
- Redis container for memory persistence. 

CI/CD Pipeline: Not implemented.

Monitoring & Logging: Application logs are structured JSON via structlog

## 7. Security Considerations

Authentication: Not implemented

Authorization: Not implemented

Data Encryption: Not implemented

Key Security Tools/Practices (recommended next steps):
- Add auth middleware / dependency in src/app/api/deps.py and apply it to /ingest and optionally /chat.
- Sanitise and validate ingestion paths

## 8. Development & Testing Environment

Local Setup Instructions: Run `docker compose up --build` to start app, qdrant, and redis, then open `http://localhost:8000/` for the demo UI.

Testing Frameworks: Pytest and pytest-asyncio are included in dependencies. 

Code Quality Tools: Not implemented. 

## 9. Project Identification

Project Name: Multi-Agent Enterprise RAG

Repository URL: [https://github.com/pchainieux/MultiAgentEnterpriseRAG]

Primary Contact/Team: Paul Chainieux

Date of Last Update: [2026-01-10]

